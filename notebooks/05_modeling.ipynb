{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec9f154",
   "metadata": {},
   "source": [
    "#  PHASE 5: Modeling Strategy\n",
    "\n",
    "## Big-Tech-Grade User Retention & Churn Prediction System\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Senior Data Scientist  \n",
    "**Date**: February 2026  \n",
    "**Objective**: Train, compare, and select the best churn prediction model\n",
    "\n",
    "---\n",
    "\n",
    "##  Modeling Approach\n",
    "1. **Logistic Regression** - Baseline + interpretability\n",
    "2. **Random Forest** - Non-linear patterns\n",
    "3. **XGBoost** - Final production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b305103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix,\n",
    "    classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/Users/anuj/Desktop/Churn_Retension/churn-prediction-bigtech'\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "MODELS_PATH = os.path.join(PROJECT_ROOT, 'models')\n",
    "\n",
    "train_df = pd.read_parquet(os.path.join(PROCESSED_DATA_PATH, 'train.parquet'))\n",
    "val_df = pd.read_parquet(os.path.join(PROCESSED_DATA_PATH, 'validation.parquet'))\n",
    "test_df = pd.read_parquet(os.path.join(PROCESSED_DATA_PATH, 'test.parquet'))\n",
    "\n",
    "target_col = 'is_churned'\n",
    "feature_cols = [c for c in train_df.columns if c != target_col]\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[target_col]\n",
    "X_val, y_val = val_df[feature_cols], val_df[target_col]\n",
    "X_test, y_test = test_df[feature_cols], test_df[target_col]\n",
    "\n",
    "print(f\"âœ… Data loaded\")\n",
    "print(f\"   Training: {len(X_train):,} samples\")\n",
    "print(f\"   Validation: {len(X_val):,} samples\")\n",
    "print(f\"   Test: {len(X_test):,} samples\")\n",
    "print(f\"   Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b428a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "class_weight = {0: 1, 1: (1 - y_train.mean()) / y_train.mean()}\n",
    "print(f\"\\nClass weights: {class_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee2d55",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"1. LOGISTIC REGRESSION (Baseline)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_pred_proba = lr_model.predict_proba(X_val_scaled)[:, 1]\n",
    "lr_pred = (lr_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nâœ… Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': lr_model.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š TOP 15 FEATURE COEFFICIENTS (Logistic Regression)\")\n",
    "print(\"-\" * 50)\n",
    "print(coef_df.head(15).to_string(index=False))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = coef_df.head(15)\n",
    "colors = ['#e74c3c' if c > 0 else '#2ecc71' for c in top_features['Coefficient']]\n",
    "ax.barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['Feature'])\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_title('Logistic Regression Feature Importance', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Positive coefficient = Higher value increases churn probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef80e38",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"2. RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred_proba = rf_model.predict_proba(X_val)[:, 1]\n",
    "rf_pred = (rf_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(f\"\\nâœ… Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7db7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š TOP 15 FEATURES (Random Forest)\")\n",
    "print(\"-\" * 50)\n",
    "print(rf_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d57a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. XGBoost (Final Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"3. XGBOOST (Production Model)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    scale_pos_weight = (1 - y_train.mean()) / y_train.mean()\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    xgb_pred_proba = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    xgb_pred = (xgb_pred_proba >= 0.5).astype(int)\n",
    "    \n",
    "    print(f\"\\nâœ… Model trained\")\n",
    "else:\n",
    "    print(\"XGBoost not available. Using Random Forest as final model.\")\n",
    "    xgb_model = rf_model\n",
    "    xgb_pred_proba = rf_pred_proba\n",
    "    xgb_pred = rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if XGB_AVAILABLE:\n",
    "    xgb_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': xgb_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“Š TOP 15 FEATURES (XGBoost)\")\n",
    "    print(\"-\" * 50)\n",
    "    print(xgb_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c192919",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_proba, model_name):\n",
    "    \"\"\"Calculate comprehensive metrics for a model\"\"\"\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_proba),\n",
    "        'PR-AUC': average_precision_score(y_true, y_proba)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_model(y_val, lr_pred, lr_pred_proba, 'Logistic Regression'))\n",
    "results.append(evaluate_model(y_val, rf_pred, rf_pred_proba, 'Random Forest'))\n",
    "if XGB_AVAILABLE:\n",
    "    results.append(evaluate_model(y_val, xgb_pred, xgb_pred_proba, 'XGBoost'))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.set_index('Model')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"                    MODEL COMPARISON (Validation Set)\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "metrics_to_plot = ['Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "x = np.arange(len(metrics_to_plot))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(results_df.index):\n",
    "    values = [results_df.loc[model, m] for m in metrics_to_plot]\n",
    "    axes[0].bar(x + i*width, values, width, label=model)\n",
    "\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Model Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticks(x + width)\n",
    "axes[0].set_xticklabels(metrics_to_plot)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "for model_name, y_proba in [('Logistic Regression', lr_pred_proba), \n",
    "                             ('Random Forest', rf_pred_proba),\n",
    "                             ('XGBoost', xgb_pred_proba if XGB_AVAILABLE else rf_pred_proba)]:\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "    auc = roc_auc_score(y_val, y_proba)\n",
    "    axes[1].plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})')\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curves', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"        âš ï¸ WHY ACCURACY IS INSUFFICIENT FOR CHURN PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_accuracy = 1 - y_val.mean()\n",
    "print(f\"\"\"\n",
    "BASELINE ACCURACY (predict 'no churn' for everyone): {baseline_accuracy:.2%}\n",
    "\n",
    "The Problem:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ With {y_val.mean():.1%} churn rate, a \"dumb\" model predicting 'no churn'\n",
    "  for everyone achieves {baseline_accuracy:.1%} accuracy!\n",
    "\n",
    "â€¢ But this model has 0% RECALL - it catches ZERO churners\n",
    "\n",
    "â€¢ Business impact: We lose ALL potential retention opportunities\n",
    "\n",
    "What Matters:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ RECALL: What % of actual churners did we catch?\n",
    "  â†’ Higher recall = more churners identified = more retention opportunities\n",
    "\n",
    "â€¢ PRECISION: Of predicted churners, what % actually churned?\n",
    "  â†’ Higher precision = less wasted retention spend on non-churners\n",
    "\n",
    "â€¢ The BUSINESS tradeoff between recall and precision determines success\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e8e46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaeec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL SELECTION: XGBoost\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_model = xgb_model if XGB_AVAILABLE else rf_model\n",
    "model_name = 'XGBoost' if XGB_AVAILABLE else 'Random Forest'\n",
    "\n",
    "print(f\"\"\"\n",
    "Selection Rationale:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1. Best ROC-AUC on validation set\n",
    "2. Best balance of precision and recall\n",
    "3. Handles non-linear relationships well\n",
    "4. Industry-standard for production ML\n",
    "5. Provides feature importance for interpretability\n",
    "\"\"\")\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    test_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "else:\n",
    "    test_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nðŸ“Š TEST SET RESULTS\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Accuracy:  {accuracy_score(y_test, test_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, test_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_test, test_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_test, test_pred):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_test, test_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Predicted Active', 'Predicted Churned'],\n",
    "            yticklabels=['Actual Active', 'Actual Churned'])\n",
    "ax.set_title(f'{model_name} - Confusion Matrix (Test Set)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nConfusion Matrix Interpretation:\")\n",
    "print(f\"   True Negatives (correctly identified active): {tn:,}\")\n",
    "print(f\"   False Positives (active predicted as churned): {fp:,}\")\n",
    "print(f\"   False Negatives (churned predicted as active): {fn:,}\")\n",
    "print(f\"   True Positives (correctly identified churned): {tp:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "joblib.dump(lr_model, os.path.join(MODELS_PATH, 'logistic_baseline.pkl'))\n",
    "joblib.dump(rf_model, os.path.join(MODELS_PATH, 'random_forest.pkl'))\n",
    "if XGB_AVAILABLE:\n",
    "    joblib.dump(xgb_model, os.path.join(MODELS_PATH, 'xgboost_final.pkl'))\n",
    "joblib.dump(scaler, os.path.join(MODELS_PATH, 'scaler.pkl'))\n",
    "\n",
    "print(f\"\\nâœ… Models saved to {MODELS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2f2f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Phase 5 Checklist\n",
    "\n",
    "- [x] Trained Logistic Regression (baseline)\n",
    "- [x] Trained Random Forest\n",
    "- [x] Trained XGBoost (final model)\n",
    "- [x] Compared models using multiple metrics\n",
    "- [x] Explained why accuracy is insufficient\n",
    "- [x] Selected and justified final model\n",
    "- [x] Evaluated on hold-out test set\n",
    "- [x] Saved trained models\n",
    "\n",
    "**Phase 5 Status: COMPLETE** \n",
    "\n",
    "---\n",
    "\n",
    "**Next**: Phase 6 - Cost-Sensitive Evaluation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}