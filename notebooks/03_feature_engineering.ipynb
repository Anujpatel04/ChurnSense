{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879481e5",
   "metadata": {},
   "source": [
    "#  PHASE 3: Feature Engineering\n",
    "\n",
    "## Big-Tech-Grade User Retention & Churn Prediction System\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Senior Data Scientist  \n",
    "**Date**: February 2026  \n",
    "**Objective**: Engineer behavioral features with business rationale for churn prediction\n",
    "\n",
    "---\n",
    "\n",
    "##  Feature Categories\n",
    "1. **Recency Features** - Time since last activity\n",
    "2. **Frequency Features** - Purchase patterns\n",
    "3. **Monetary Features** - Spending behavior\n",
    "4. **Trend Features** - Behavioral changes over time\n",
    "5. **Engagement Features** - Product and basket patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43116681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ROOT = '/Users/anuj/Desktop/Churn_Retension/churn-prediction-bigtech'\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "\n",
    "df = pd.read_parquet(os.path.join(PROCESSED_DATA_PATH, 'transactions_clean.parquet'))\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "OBSERVATION_DATE = pd.Timestamp('2011-10-10')\n",
    "CHURN_WINDOW = 60\n",
    "\n",
    "print(f\"âœ… Loaded {len(df):,} transactions\")\n",
    "print(f\"   Date range: {df['InvoiceDate'].min().date()} to {df['InvoiceDate'].max().date()}\")\n",
    "print(f\"   Observation date: {OBSERVATION_DATE.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = df[df['InvoiceDate'] <= OBSERVATION_DATE].copy()\n",
    "\n",
    "df_hist['Revenue'] = df_hist['Quantity'] * df_hist['Price']\n",
    "\n",
    "print(f\"Historical data for feature engineering: {len(df_hist):,} transactions\")\n",
    "print(f\"Unique customers: {df_hist['Customer ID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80abe6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Recency Features\n",
    "\n",
    "**Business Rationale**: Recency is the strongest predictor of churn. Customers who haven't purchased recently are more likely to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"1. RECENCY FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "recency_features = df_hist.groupby('Customer ID').agg(\n",
    "    last_purchase_date=('InvoiceDate', 'max'),\n",
    "    first_purchase_date=('InvoiceDate', 'min')\n",
    ").reset_index()\n",
    "\n",
    "recency_features['recency_days'] = (OBSERVATION_DATE - recency_features['last_purchase_date']).dt.days\n",
    "\n",
    "recency_features['tenure_days'] = (OBSERVATION_DATE - recency_features['first_purchase_date']).dt.days\n",
    "\n",
    "recency_features['active_period_days'] = (recency_features['last_purchase_date'] - recency_features['first_purchase_date']).dt.days\n",
    "\n",
    "recency_features['recency_ratio'] = recency_features['recency_days'] / recency_features['tenure_days'].clip(lower=1)\n",
    "\n",
    "recency_features['is_recent_30d'] = (recency_features['recency_days'] <= 30).astype(int)\n",
    "\n",
    "print(\"\\nRecency Features Created:\")\n",
    "print(\"-\" * 50)\n",
    "feature_explanations = {\n",
    "    'recency_days': 'Days since last purchase - Primary churn indicator',\n",
    "    'tenure_days': 'Customer tenure - Longer tenure = more invested',\n",
    "    'active_period_days': 'Time between first and last purchase',\n",
    "    'recency_ratio': 'Recency relative to tenure - Normalized measure',\n",
    "    'is_recent_30d': 'Binary: purchased in last 30 days'\n",
    "}\n",
    "for feat, expl in feature_explanations.items():\n",
    "    print(f\"   {feat}: {expl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60822c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Frequency Features\n",
    "\n",
    "**Business Rationale**: Purchase frequency indicates engagement level. Frequent buyers are more committed to the brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"2. FREQUENCY FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "frequency_features = df_hist.groupby('Customer ID').agg(\n",
    "    total_orders=('Invoice', 'nunique'),\n",
    "    \n",
    "    total_transactions=('Invoice', 'count'),\n",
    "    \n",
    "    active_days=('InvoiceDate', lambda x: x.dt.date.nunique()),\n",
    "    \n",
    "    first_purchase=('InvoiceDate', 'min'),\n",
    "    last_purchase=('InvoiceDate', 'max')\n",
    ").reset_index()\n",
    "\n",
    "frequency_features['tenure_months'] = ((OBSERVATION_DATE - frequency_features['first_purchase']).dt.days / 30).clip(lower=0.5)\n",
    "frequency_features['orders_per_month'] = frequency_features['total_orders'] / frequency_features['tenure_months']\n",
    "\n",
    "frequency_features['active_period'] = (frequency_features['last_purchase'] - frequency_features['first_purchase']).dt.days\n",
    "frequency_features['avg_days_between_orders'] = frequency_features['active_period'] / (frequency_features['total_orders'] - 1).clip(lower=1)\n",
    "\n",
    "def calculate_purchase_regularity(group):\n",
    "    \"\"\"Calculate standard deviation of days between purchases\"\"\"\n",
    "    dates = group['InvoiceDate'].dt.normalize().drop_duplicates().sort_values()\n",
    "    if len(dates) < 2:\n",
    "        return np.nan\n",
    "    intervals = dates.diff().dt.days.dropna()\n",
    "    return intervals.std() if len(intervals) > 0 else np.nan\n",
    "\n",
    "purchase_regularity = df_hist.groupby('Customer ID').apply(calculate_purchase_regularity).reset_index()\n",
    "purchase_regularity.columns = ['Customer ID', 'purchase_interval_std']\n",
    "\n",
    "frequency_features = frequency_features.merge(purchase_regularity, on='Customer ID', how='left')\n",
    "\n",
    "frequency_features['is_single_order'] = (frequency_features['total_orders'] == 1).astype(int)\n",
    "\n",
    "freq_cols = ['Customer ID', 'total_orders', 'total_transactions', 'active_days', \n",
    "             'orders_per_month', 'avg_days_between_orders', 'purchase_interval_std', 'is_single_order']\n",
    "frequency_features = frequency_features[freq_cols]\n",
    "\n",
    "print(\"\\nFrequency Features Created:\")\n",
    "print(\"-\" * 50)\n",
    "freq_explanations = {\n",
    "    'total_orders': 'Total unique orders - Core engagement metric',\n",
    "    'total_transactions': 'Total line items - Measures basket complexity',\n",
    "    'active_days': 'Days with at least one purchase',\n",
    "    'orders_per_month': 'Purchase velocity - Normalized by tenure',\n",
    "    'avg_days_between_orders': 'Average purchase interval',\n",
    "    'purchase_interval_std': 'Consistency of purchase timing',\n",
    "    'is_single_order': 'One-time buyer flag (high risk)'\n",
    "}\n",
    "for feat, expl in freq_explanations.items():\n",
    "    print(f\"   {feat}: {expl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5236dd0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Monetary Features\n",
    "\n",
    "**Business Rationale**: Customer value determines retention investment priority. High-value customers justify more retention effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32567fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"3. MONETARY FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "order_values = df_hist.groupby(['Customer ID', 'Invoice']).agg(\n",
    "    order_revenue=('Revenue', 'sum'),\n",
    "    order_quantity=('Quantity', 'sum'),\n",
    "    order_items=('StockCode', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "monetary_features = order_values.groupby('Customer ID').agg(\n",
    "    total_revenue=('order_revenue', 'sum'),\n",
    "    \n",
    "    avg_order_value=('order_revenue', 'mean'),\n",
    "    \n",
    "    max_order_value=('order_revenue', 'max'),\n",
    "    \n",
    "    min_order_value=('order_revenue', 'min'),\n",
    "    \n",
    "    order_value_std=('order_revenue', 'std'),\n",
    "    \n",
    "    total_quantity=('order_quantity', 'sum'),\n",
    "    \n",
    "    avg_items_per_order=('order_items', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "active_days_temp = df_hist.groupby('Customer ID')['InvoiceDate'].apply(lambda x: x.dt.date.nunique()).reset_index()\n",
    "active_days_temp.columns = ['Customer ID', 'active_days_count']\n",
    "monetary_features = monetary_features.merge(active_days_temp, on='Customer ID')\n",
    "monetary_features['revenue_per_active_day'] = monetary_features['total_revenue'] / monetary_features['active_days_count']\n",
    "\n",
    "monetary_features['order_value_cv'] = monetary_features['order_value_std'] / monetary_features['avg_order_value'].clip(lower=0.01)\n",
    "\n",
    "monetary_features = monetary_features.drop('active_days_count', axis=1)\n",
    "monetary_features['order_value_std'] = monetary_features['order_value_std'].fillna(0)\n",
    "monetary_features['order_value_cv'] = monetary_features['order_value_cv'].fillna(0)\n",
    "\n",
    "print(\"\\nMonetary Features Created:\")\n",
    "print(\"-\" * 50)\n",
    "mon_explanations = {\n",
    "    'total_revenue': 'Total customer spend - Customer lifetime value proxy',\n",
    "    'avg_order_value': 'Average basket size - Spending tier indicator',\n",
    "    'max_order_value': 'Largest single order - Peak spending capacity',\n",
    "    'min_order_value': 'Smallest order - Floor spending behavior',\n",
    "    'order_value_std': 'Spending variability',\n",
    "    'total_quantity': 'Total items purchased',\n",
    "    'avg_items_per_order': 'Basket complexity',\n",
    "    'revenue_per_active_day': 'Daily spending intensity',\n",
    "    'order_value_cv': 'Spending consistency (lower = more consistent)'\n",
    "}\n",
    "for feat, expl in mon_explanations.items():\n",
    "    print(f\"   {feat}: {expl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4138b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Trend Features (CRITICAL)\n",
    "\n",
    "**Business Rationale**: Behavioral changes are early warning signals. Declining engagement predicts churn better than static metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a07e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"4. TREND FEATURES (Early Warning Signals)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_trend_features(df_hist, observation_date):\n",
    "    \"\"\"Calculate trend features comparing early vs recent behavior\"\"\"\n",
    "    \n",
    "    customer_dates = df_hist.groupby('Customer ID').agg(\n",
    "        first_purchase=('InvoiceDate', 'min'),\n",
    "        last_purchase=('InvoiceDate', 'max')\n",
    "    ).reset_index()\n",
    "    \n",
    "    customer_dates['midpoint'] = customer_dates['first_purchase'] + \\\n",
    "        (customer_dates['last_purchase'] - customer_dates['first_purchase']) / 2\n",
    "    \n",
    "    df_trend = df_hist.merge(customer_dates[['Customer ID', 'midpoint', 'first_purchase']], on='Customer ID')\n",
    "    \n",
    "    df_trend['period'] = np.where(df_trend['InvoiceDate'] <= df_trend['midpoint'], 'early', 'recent')\n",
    "    \n",
    "    period_stats = df_trend.groupby(['Customer ID', 'period']).agg(\n",
    "        orders=('Invoice', 'nunique'),\n",
    "        revenue=('Revenue', 'sum'),\n",
    "        quantity=('Quantity', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    period_pivot = period_stats.pivot(index='Customer ID', columns='period', values=['orders', 'revenue', 'quantity'])\n",
    "    period_pivot.columns = [f'{col[0]}_{col[1]}' for col in period_pivot.columns]\n",
    "    period_pivot = period_pivot.reset_index().fillna(0)\n",
    "    \n",
    "    period_pivot['order_trend'] = (period_pivot.get('orders_recent', 0) - period_pivot.get('orders_early', 0)) / \\\n",
    "                                   period_pivot.get('orders_early', 1).clip(lower=1)\n",
    "    \n",
    "    period_pivot['revenue_trend'] = (period_pivot.get('revenue_recent', 0) - period_pivot.get('revenue_early', 0)) / \\\n",
    "                                     period_pivot.get('revenue_early', 1).clip(lower=1)\n",
    "    \n",
    "    period_pivot['quantity_trend'] = (period_pivot.get('quantity_recent', 0) - period_pivot.get('quantity_early', 0)) / \\\n",
    "                                      period_pivot.get('quantity_early', 1).clip(lower=1)\n",
    "    \n",
    "    period_pivot['is_declining'] = ((period_pivot['order_trend'] < 0) | \n",
    "                                    (period_pivot['revenue_trend'] < 0)).astype(int)\n",
    "    \n",
    "    return period_pivot[['Customer ID', 'order_trend', 'revenue_trend', 'quantity_trend', 'is_declining']]\n",
    "\n",
    "trend_features = calculate_trend_features(df_hist, OBSERVATION_DATE)\n",
    "\n",
    "def calculate_recent_trend(df_hist, observation_date):\n",
    "    \"\"\"Compare last 30 days vs 31-60 days ago\"\"\"\n",
    "    \n",
    "    last_30 = df_hist[df_hist['InvoiceDate'] > (observation_date - timedelta(days=30))]\n",
    "    prev_30 = df_hist[(df_hist['InvoiceDate'] > (observation_date - timedelta(days=60))) & \n",
    "                      (df_hist['InvoiceDate'] <= (observation_date - timedelta(days=30)))]\n",
    "    \n",
    "    last_30_stats = last_30.groupby('Customer ID').agg(\n",
    "        orders_last30=('Invoice', 'nunique'),\n",
    "        revenue_last30=('Revenue', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    prev_30_stats = prev_30.groupby('Customer ID').agg(\n",
    "        orders_prev30=('Invoice', 'nunique'),\n",
    "        revenue_prev30=('Revenue', 'sum')\n",
    "    ).reset_index()\n",
    "    \n",
    "    all_customers = df_hist[['Customer ID']].drop_duplicates()\n",
    "    recent_trend = all_customers.merge(last_30_stats, on='Customer ID', how='left')\n",
    "    recent_trend = recent_trend.merge(prev_30_stats, on='Customer ID', how='left')\n",
    "    recent_trend = recent_trend.fillna(0)\n",
    "    \n",
    "    recent_trend['recent_order_momentum'] = recent_trend['orders_last30'] - recent_trend['orders_prev30']\n",
    "    \n",
    "    recent_trend['recent_revenue_momentum'] = recent_trend['revenue_last30'] - recent_trend['revenue_prev30']\n",
    "    \n",
    "    return recent_trend[['Customer ID', 'orders_last30', 'revenue_last30', \n",
    "                         'recent_order_momentum', 'recent_revenue_momentum']]\n",
    "\n",
    "recent_trend_features = calculate_recent_trend(df_hist, OBSERVATION_DATE)\n",
    "trend_features = trend_features.merge(recent_trend_features, on='Customer ID', how='left').fillna(0)\n",
    "\n",
    "print(\"\\nTrend Features Created:\")\n",
    "print(\"-\" * 50)\n",
    "trend_explanations = {\n",
    "    'order_trend': 'Change in order frequency (recent vs early) - KEY PREDICTOR',\n",
    "    'revenue_trend': 'Change in spending (spend decay rate) - KEY PREDICTOR',\n",
    "    'quantity_trend': 'Change in items purchased',\n",
    "    'is_declining': 'Binary: any declining behavior signal',\n",
    "    'orders_last30': 'Orders in most recent 30 days',\n",
    "    'revenue_last30': 'Revenue in most recent 30 days',\n",
    "    'recent_order_momentum': 'Order change: last 30d vs prev 30d',\n",
    "    'recent_revenue_momentum': 'Revenue change: last 30d vs prev 30d'\n",
    "}\n",
    "for feat, expl in trend_explanations.items():\n",
    "    print(f\"   {feat}: {expl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b0308",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Engagement Features\n",
    "\n",
    "**Business Rationale**: Product diversity and basket patterns indicate engagement depth and switching costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"5. ENGAGEMENT FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "engagement_features = df_hist.groupby('Customer ID').agg(\n",
    "    unique_products=('StockCode', 'nunique'),\n",
    "    \n",
    "    unique_descriptions=('Description', 'nunique'),\n",
    "    \n",
    "    total_line_items=('Invoice', 'count')\n",
    ").reset_index()\n",
    "\n",
    "products_per_order = df_hist.groupby(['Customer ID', 'Invoice'])['StockCode'].nunique().reset_index()\n",
    "products_per_order = products_per_order.groupby('Customer ID')['StockCode'].mean().reset_index()\n",
    "products_per_order.columns = ['Customer ID', 'avg_products_per_order']\n",
    "engagement_features = engagement_features.merge(products_per_order, on='Customer ID')\n",
    "\n",
    "product_counts = df_hist.groupby(['Customer ID', 'StockCode']).size().reset_index(name='product_purchases')\n",
    "product_concentration = product_counts.groupby('Customer ID')['product_purchases'].agg(['max', 'sum']).reset_index()\n",
    "product_concentration.columns = ['Customer ID', 'max_product_purchases', 'total_product_purchases']\n",
    "product_concentration['product_concentration'] = product_concentration['max_product_purchases'] / product_concentration['total_product_purchases']\n",
    "engagement_features = engagement_features.merge(product_concentration[['Customer ID', 'product_concentration']], on='Customer ID')\n",
    "\n",
    "customer_country = df_hist.groupby('Customer ID')['Country'].first().reset_index()\n",
    "customer_country['is_uk'] = (customer_country['Country'] == 'United Kingdom').astype(int)\n",
    "engagement_features = engagement_features.merge(customer_country[['Customer ID', 'is_uk']], on='Customer ID')\n",
    "\n",
    "print(\"\\nEngagement Features Created:\")\n",
    "print(\"-\" * 50)\n",
    "eng_explanations = {\n",
    "    'unique_products': 'Product diversity - Higher = more engaged',\n",
    "    'unique_descriptions': 'Category diversity',\n",
    "    'total_line_items': 'Total transaction count',\n",
    "    'avg_products_per_order': 'Basket complexity - Exploration behavior',\n",
    "    'product_concentration': 'Repeat purchase focus (0-1, higher = more focused)',\n",
    "    'is_uk': 'Domestic vs international customer'\n",
    "}\n",
    "for feat, expl in eng_explanations.items():\n",
    "    print(f\"   {feat}: {expl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b22ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0538b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COMBINING ALL FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "features_df = recency_features[['Customer ID', 'recency_days', 'tenure_days', \n",
    "                                 'active_period_days', 'recency_ratio', 'is_recent_30d']].copy()\n",
    "\n",
    "features_df = features_df.merge(frequency_features, on='Customer ID', how='left')\n",
    "\n",
    "features_df = features_df.merge(monetary_features, on='Customer ID', how='left')\n",
    "\n",
    "features_df = features_df.merge(trend_features, on='Customer ID', how='left')\n",
    "\n",
    "features_df = features_df.merge(engagement_features, on='Customer ID', how='left')\n",
    "\n",
    "print(f\"\\nâœ… Combined feature dataset:\")\n",
    "print(f\"   Customers: {len(features_df):,}\")\n",
    "print(f\"   Features: {len(features_df.columns) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "missing = features_df.isnull().sum()\n",
    "missing_pct = (missing / len(features_df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Pct': missing_pct})\n",
    "missing_df = missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "    \n",
    "    print(\"\\nâ†’ Filling missing values...\")\n",
    "    \n",
    "    features_df['purchase_interval_std'] = features_df['purchase_interval_std'].fillna(0)\n",
    "    features_df['order_value_std'] = features_df['order_value_std'].fillna(0)\n",
    "    features_df['order_value_cv'] = features_df['order_value_cv'].fillna(0)\n",
    "    \n",
    "    numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
    "    features_df[numeric_cols] = features_df[numeric_cols].fillna(0)\n",
    "else:\n",
    "    print(\"No missing values!\")\n",
    "\n",
    "print(f\"\\nâœ… Final missing values: {features_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f563dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š FEATURE SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_cols = [c for c in features_df.columns if c != 'Customer ID']\n",
    "features_df[feature_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c66d3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Feature Rationale Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e55ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"                    FEATURE RATIONALE DOCUMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_documentation = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         RECENCY FEATURES                                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ recency_days          â”‚ Days since last purchase. THE strongest churn       â”‚\n",
    "â”‚                       â”‚ predictor. Higher = more likely to churn.           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ tenure_days           â”‚ Days since first purchase. Longer tenure indicates  â”‚\n",
    "â”‚                       â”‚ more invested customers who are less likely to      â”‚\n",
    "â”‚                       â”‚ churn.                                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ recency_ratio         â”‚ Recency normalized by tenure. A customer with 100   â”‚\n",
    "â”‚                       â”‚ day tenure and 50 day recency has same ratio as     â”‚\n",
    "â”‚                       â”‚ 200 day tenure and 100 day recency.                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        FREQUENCY FEATURES                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ total_orders          â”‚ Total unique orders. More orders = more engaged     â”‚\n",
    "â”‚                       â”‚ = less likely to churn. Critical for identifying    â”‚\n",
    "â”‚                       â”‚ one-time buyers (highest churn risk).               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ orders_per_month      â”‚ Purchase velocity normalized by customer age.       â”‚\n",
    "â”‚                       â”‚ Accounts for customers at different lifecycle       â”‚\n",
    "â”‚                       â”‚ stages.                                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ purchase_interval_std â”‚ Consistency of purchase timing. Lower std = more    â”‚\n",
    "â”‚                       â”‚ regular buyer = less likely to churn unexpectedly.  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        MONETARY FEATURES                                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ total_revenue         â”‚ Customer lifetime value proxy. Higher value =       â”‚\n",
    "â”‚                       â”‚ more invested in relationship = less likely to      â”‚\n",
    "â”‚                       â”‚ churn. Also determines retention investment.        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ avg_order_value       â”‚ Spending tier indicator. Premium customers behave   â”‚\n",
    "â”‚                       â”‚ differently than budget customers.                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ order_value_cv        â”‚ Coefficient of variation of order values.           â”‚\n",
    "â”‚                       â”‚ Consistent spenders (low CV) are more predictable.  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TREND FEATURES (CRITICAL!)                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ order_trend           â”‚ Change in purchase frequency between first half     â”‚\n",
    "â”‚                       â”‚ and second half of customer journey. Negative =     â”‚\n",
    "â”‚                       â”‚ declining engagement = EARLY WARNING SIGNAL.        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ revenue_trend         â”‚ Change in spending (spend decay rate). Negative     â”‚\n",
    "â”‚                       â”‚ trend indicates customer is disengaging before      â”‚\n",
    "â”‚                       â”‚ full churn.                                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ recent_order_momentum â”‚ Orders in last 30 days vs previous 30 days.         â”‚\n",
    "â”‚                       â”‚ Captures very recent behavioral shifts.             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       ENGAGEMENT FEATURES                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ unique_products       â”‚ Product diversity. More products explored =         â”‚\n",
    "â”‚                       â”‚ deeper engagement = higher switching costs.         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ product_concentration â”‚ Do they buy same products repeatedly? High          â”‚\n",
    "â”‚                       â”‚ concentration = habitual buyer (good for            â”‚\n",
    "â”‚                       â”‚ retention but vulnerable if product unavailable).   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "print(feature_documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d755779",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb744dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(PROCESSED_DATA_PATH, 'customer_features.parquet')\n",
    "features_df.to_parquet(output_path, index=False)\n",
    "print(f\"\\nâœ… Features saved to: {output_path}\")\n",
    "print(f\"   Shape: {features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"              FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_categories = {\n",
    "    'Recency': ['recency_days', 'tenure_days', 'active_period_days', 'recency_ratio', 'is_recent_30d'],\n",
    "    'Frequency': ['total_orders', 'total_transactions', 'active_days', 'orders_per_month', \n",
    "                  'avg_days_between_orders', 'purchase_interval_std', 'is_single_order'],\n",
    "    'Monetary': ['total_revenue', 'avg_order_value', 'max_order_value', 'min_order_value',\n",
    "                 'order_value_std', 'total_quantity', 'avg_items_per_order', \n",
    "                 'revenue_per_active_day', 'order_value_cv'],\n",
    "    'Trend': ['order_trend', 'revenue_trend', 'quantity_trend', 'is_declining',\n",
    "              'orders_last30', 'revenue_last30', 'recent_order_momentum', 'recent_revenue_momentum'],\n",
    "    'Engagement': ['unique_products', 'unique_descriptions', 'total_line_items',\n",
    "                   'avg_products_per_order', 'product_concentration', 'is_uk']\n",
    "}\n",
    "\n",
    "total_features = 0\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"\\n{category} Features: {len(features)}\")\n",
    "    for f in features:\n",
    "        if f in features_df.columns:\n",
    "            print(f\"   âœ“ {f}\")\n",
    "            total_features += 1\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TOTAL FEATURES: {total_features}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60ee27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Phase 3 Checklist\n",
    "\n",
    "- [x] Created Recency features (5 features)\n",
    "- [x] Created Frequency features (7 features)\n",
    "- [x] Created Monetary features (9 features)\n",
    "- [x] Created Trend features (8 features) - KEY PREDICTORS\n",
    "- [x] Created Engagement features (6 features)\n",
    "- [x] Documented business rationale for each feature\n",
    "- [x] Handled missing values\n",
    "- [x] Saved feature dataset\n",
    "\n",
    "**Phase 3 Status: COMPLETE** \n",
    "\n",
    "---\n",
    "\n",
    "**Next**: Phase 4 - Label Creation & Data Leakage Control"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}